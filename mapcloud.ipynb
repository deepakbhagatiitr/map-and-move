{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80e74f29-baec-4c3a-9f52-6d92f346a04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/deepak-bhagat/software/Autonomous/Slamandpath\n",
      "                0            1            2            3            4   \\\n",
      "count  4541.000000  4541.000000  4541.000000  4541.000000  4541.000000   \n",
      "mean      0.077408     0.034070    -0.012741    22.378433     0.009753   \n",
      "std       0.691782     0.024297     0.716764   142.014459     0.041641   \n",
      "min      -0.999939    -0.066186    -0.999054  -271.280600    -0.081747   \n",
      "25%      -0.584706     0.016139    -0.875506   -59.754040    -0.023489   \n",
      "50%      -0.012153     0.033974    -0.002484    10.714580     0.005515   \n",
      "75%       0.895636     0.053932     0.741525   132.663600     0.038189   \n",
      "max       1.000000     0.093741     0.999995   292.239500     0.110780   \n",
      "\n",
      "                5            6            7            8            9   \\\n",
      "count  4541.000000  4541.000000  4541.000000  4541.000000  4541.000000   \n",
      "mean      0.998450     0.014748    -7.904195     0.013595     0.027745   \n",
      "std       0.001302     0.032392     6.214197     0.716694     0.023971   \n",
      "min       0.993258    -0.063186   -22.294660    -0.999984    -0.042095   \n",
      "25%       0.997797    -0.015162   -12.011660    -0.737556     0.011747   \n",
      "50%       0.998734     0.011974    -7.488594     0.003846     0.027725   \n",
      "75%       0.999506     0.046702    -3.079246     0.875843     0.044813   \n",
      "max       1.000000     0.080471     3.225534     0.999993     0.087402   \n",
      "\n",
      "                10           11  \n",
      "count  4541.000000  4541.000000  \n",
      "mean      0.077477   230.699902  \n",
      "std       0.692124   131.487950  \n",
      "min      -0.999227   -17.604910  \n",
      "25%      -0.584576   116.299900  \n",
      "50%      -0.010953   238.441600  \n",
      "75%       0.895550   359.411700  \n",
      "max       1.000000   478.591500  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1365039/2491994652.py:10: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  poses = pd.read_csv(file_path, delim_whitespace=True, header=None)  # Use whitespace delimiter for space-separated files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())  # Check your working directory\n",
    "\n",
    "# Ensure the file exists before reading\n",
    "file_path = \"/home/deepak-bhagat/Downloads/data_odometry_poses/dataset/poses/00.txt\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    poses = pd.read_csv(file_path, delim_whitespace=True, header=None)  # Use whitespace delimiter for space-separated files\n",
    "    print(poses.describe())\n",
    "else:\n",
    "    print(f\"Error: File not found at {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed628daf-66dc-4a5d-b06d-8100931758df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             0             1             2             3             4   \\\n",
       "0     1.000000  9.043680e-12  2.326809e-11  5.551115e-17  9.043683e-12   \n",
       "1     0.999998  5.272628e-04 -2.066935e-03 -4.690294e-02 -5.296506e-04   \n",
       "2     0.999991  1.048972e-03 -4.131348e-03 -9.374345e-02 -1.058514e-03   \n",
       "3     0.999980  1.566466e-03 -6.198571e-03 -1.406429e-01 -1.587952e-03   \n",
       "4     0.999964  2.078471e-03 -8.263498e-03 -1.874858e-01 -2.116664e-03   \n",
       "...        ...           ...           ...           ...           ...   \n",
       "4536  0.998794  3.096949e-03 -4.901132e-02 -5.369648e+00 -3.267539e-03   \n",
       "4537  0.998841 -1.632819e-03 -4.811549e-02 -5.418986e+00  1.437775e-03   \n",
       "4538  0.998874 -4.879842e-03 -4.718123e-02 -5.470861e+00  4.550713e-03   \n",
       "4539  0.998887 -7.351853e-03 -4.658741e-02 -5.524006e+00  6.830398e-03   \n",
       "4540  0.998909 -9.331753e-03 -4.575093e-02 -5.583931e+00  8.633629e-03   \n",
       "\n",
       "            5             6             7             8             9   \\\n",
       "0     1.000000  2.392370e-10  3.330669e-16  2.326810e-11  2.392370e-10   \n",
       "1     0.999999 -1.154865e-03 -2.839928e-02  2.066324e-03  1.155958e-03   \n",
       "2     0.999997 -2.308104e-03 -5.676064e-02  4.128913e-03  2.312456e-03   \n",
       "3     0.999993 -3.462706e-03 -8.515762e-02  6.193102e-03  3.472479e-03   \n",
       "4     0.999987 -4.615826e-03 -1.135202e-01  8.253797e-03  4.633149e-03   \n",
       "...        ...           ...           ...           ...           ...   \n",
       "4536  0.999989 -3.400893e-03 -3.459248e+00  4.900023e-02  3.556936e-03   \n",
       "4537  0.999991 -4.088007e-03 -3.482548e+00  4.812171e-02  4.014088e-03   \n",
       "4538  0.999965 -7.080753e-03 -3.498163e+00  4.721411e-02  6.858075e-03   \n",
       "4539  0.999912 -1.134240e-02 -3.526732e+00  4.666671e-02  1.101157e-02   \n",
       "4540  0.999844 -1.543319e-02 -3.562758e+00  4.588779e-02  1.502136e-02   \n",
       "\n",
       "            10            11  \n",
       "0     1.000000 -4.440892e-16  \n",
       "1     0.999997  8.586941e-01  \n",
       "2     0.999989  1.716275e+00  \n",
       "3     0.999975  2.574964e+00  \n",
       "4     0.999955  3.432648e+00  \n",
       "...        ...           ...  \n",
       "4536  0.998792  9.243554e+01  \n",
       "4537  0.998833  9.356768e+01  \n",
       "4538  0.998861  9.470089e+01  \n",
       "4539  0.998850  9.582761e+01  \n",
       "4540  0.998834  9.696153e+01  \n",
       "\n",
       "[4541 rows x 12 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "193131a2-b344-42de-88eb-7fec2786841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth poses are not avaialble for sequence 00.\n",
      "Number of frames: 4541\n",
      "Calibration data for camera 0 (intrinsics):\n",
      " [[718.856    0.     607.1928]\n",
      " [  0.     718.856  185.2157]\n",
      " [  0.       0.       1.    ]]\n",
      "First timestamp: 0:00:00\n",
      "No ground truth poses available.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo ground truth poses available.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# 2. Access and visualize the first LiDAR scan\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m velo_scan = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_velo\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShape of first LiDAR scan:\u001b[39m\u001b[33m\"\u001b[39m, velo_scan.shape)  \u001b[38;5;66;03m# Expected shape: (N, 4)\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Plot a top-down view of the LiDAR scan (using x and y coordinates, color coded by reflectance)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/Autonomous/Slamandpath/.venv/lib/python3.12/site-packages/pykitti/odometry.py:106\u001b[39m, in \u001b[36modometry.get_velo\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_velo\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m    105\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read velodyne [x,y,z,reflectance] scan at the specified index.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m utils.load_velo_scan(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvelo_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pykitti\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the base directory where your KITTI odometry dataset is stored\n",
    "basedir =\"/home/deepak-bhagat/Downloads/data_odometry_calib/dataset/\"\n",
    "\n",
    "# Specify the sequence you have (e.g., '00')\n",
    "sequence = '00'\n",
    "\n",
    "# If you only have a subset of frames, you can specify it. Otherwise, set frames=None.\n",
    "frames = None\n",
    "\n",
    "# Create an instance of the odometry class\n",
    "data = pykitti.odometry(basedir, sequence)\n",
    "\n",
    "# Since you don't have image files, avoid calling image-related methods.\n",
    "# Instead, work with LiDAR, calibration, timestamps, and poses.\n",
    "\n",
    "# 1. Print basic information\n",
    "print(\"Number of frames:\", len(data))\n",
    "print(\"Calibration data for camera 0 (intrinsics):\\n\", data.calib.K_cam0)\n",
    "print(\"First timestamp:\", data.timestamps[0])\n",
    "if data.poses:\n",
    "    print(\"First ground truth pose:\\n\", data.poses[0])\n",
    "else:\n",
    "    print(\"No ground truth poses available.\")\n",
    "\n",
    "# 2. Access and visualize the first LiDAR scan\n",
    "velo_scan = data.get_velo(0)\n",
    "print(\"Shape of first LiDAR scan:\", velo_scan.shape)  # Expected shape: (N, 4)\n",
    "\n",
    "# Plot a top-down view of the LiDAR scan (using x and y coordinates, color coded by reflectance)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(velo_scan[:, 0], velo_scan[:, 1], s=0.5, c=velo_scan[:, 3], cmap='jet')\n",
    "plt.xlabel(\"X (m)\")\n",
    "plt.ylabel(\"Y (m)\")\n",
    "plt.title(\"Top-Down View of the First LiDAR Scan\")\n",
    "plt.colorbar(label=\"Reflectance\")\n",
    "plt.show()\n",
    "\n",
    "# 3. If you want to iterate over a few LiDAR scans and check their timestamps or poses:\n",
    "for idx, (velo, timestamp) in enumerate(zip(data.velo, data.timestamps)):\n",
    "    print(f\"Frame {idx}: timestamp = {timestamp}\")\n",
    "    # Optionally, do further processing with the LiDAR data\n",
    "    if idx >= 2:  # Process only the first three scans for this example\n",
    "        break\n",
    "\n",
    "# 4. Using calibration to transform a point from the velodyne frame to camera 0 frame:\n",
    "# Create a homogeneous point (in the velodyne coordinate system)\n",
    "point_velo = np.array([0, 0, 0, 1])\n",
    "point_cam0 = data.calib.T_cam0_velo.dot(point_velo)\n",
    "print(\"Point in camera 0 coordinate system:\", point_cam0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05369c-8c00-43f0-9e9e-7585472468da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykitti\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# Set the base directory and sequence for the odometry dataset\n",
    "basedir = 'D:\\DSGRMS\\KIITI DataSet\\dataset'\n",
    "sequence = '00'\n",
    "frames = None  # Load all frames or specify a range, e.g., range(0, 50)\n",
    "\n",
    "# Create an instance of the odometry dataset\n",
    "data = pykitti.odometry(basedir, sequence, frames=frames)\n",
    "\n",
    "# Load the first LiDAR scan from the dataset\n",
    "velo_scan = data.get_velo(6)  # shape: (N, 4) -> [x, y, z, reflectance]\n",
    "\n",
    "# Extract the 3D points (x, y, z)\n",
    "points = velo_scan[:, :3]\n",
    "\n",
    "# Use reflectance for color (scaled to [0,1])\n",
    "reflectance = velo_scan[:, 3]\n",
    "colors = np.tile(reflectance.reshape(-1, 1), (1, 3))\n",
    "colors = colors / np.max(colors)  # Normalize to range [0,1]\n",
    "\n",
    "# Create an Open3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911eb393-47bf-4fe0-9ae8-7def81af3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "velo_scan = data.velo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c2f13-8e7f-4b59-93cd-244a51e1050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(velo_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651cccd-cf04-47a8-9105-1fdedbb97ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.timestamps[4540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90015c-6316-4fb8-a51e-957cc0ec2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pykitti\n",
    "import copy\n",
    "\n",
    "# --- SLAM Setup ---\n",
    "basedir =\"D:\\DSGRMS\\KIITI DataSet\\dataset\"  # Replace with your path\n",
    "sequence = '00'\n",
    "data = pykitti.odometry(basedir, sequence, frames=range(0, 10))  # For demo, use first 10 scans\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size=0.1):\n",
    "    \"\"\" Downsample and estimate normals \"\"\"\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    pcd_down.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30)\n",
    "    )\n",
    "    return pcd_down\n",
    "\n",
    "# Initialize with the first LiDAR scan\n",
    "velo_scan = data.get_velo(0)\n",
    "pcd_prev = o3d.geometry.PointCloud()\n",
    "pcd_prev.points = o3d.utility.Vector3dVector(velo_scan[:, :3])\n",
    "pcd_prev = preprocess_point_cloud(pcd_prev, voxel_size=0.1)\n",
    "\n",
    "transformation_global = np.eye(4)\n",
    "trajectory = [transformation_global.copy()]\n",
    "global_map = copy.deepcopy(pcd_prev)\n",
    "\n",
    "# SLAM Loop (using ICP to register consecutive scans)\n",
    "for i in range(1, 10):\n",
    "    velo_scan = data.get_velo(i)\n",
    "    pcd_curr = o3d.geometry.PointCloud()\n",
    "    pcd_curr.points = o3d.utility.Vector3dVector(velo_scan[:, :3])\n",
    "    pcd_curr = preprocess_point_cloud(pcd_curr, voxel_size=0.1)\n",
    "    \n",
    "    # ICP Registration (point-to-point)\n",
    "    threshold = 1.0  # max correspondence distance\n",
    "    icp_result = o3d.pipelines.registration.registration_icp(\n",
    "        pcd_curr, pcd_prev, threshold, np.eye(4),\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    \n",
    "    # Update global transformation and trajectory\n",
    "    transformation_global = transformation_global @ icp_result.transformation\n",
    "    trajectory.append(transformation_global.copy())\n",
    "    \n",
    "    # Transform current point cloud into the global coordinate frame\n",
    "    pcd_curr_transformed = copy.deepcopy(pcd_curr)\n",
    "    pcd_curr_transformed.transform(transformation_global)\n",
    "    global_map += pcd_curr_transformed\n",
    "    global_map = global_map.voxel_down_sample(0.1)\n",
    "    \n",
    "    # Prepare for next iteration\n",
    "    pcd_prev = pcd_curr\n",
    "    print(f\"Processed frame {i}\")\n",
    "\n",
    "# Visualize the global map and trajectory\n",
    "print(\"Estimated Trajectory Poses:\")\n",
    "for pose in trajectory:\n",
    "    print(pose)\n",
    "\n",
    "o3d.visualization.draw_geometries([global_map])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
