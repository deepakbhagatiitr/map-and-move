{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e74f29-baec-4c3a-9f52-6d92f346a04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/deepak-bhagat/software/Autonomous/Slamandpath\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/deepak-bhagat/software/Autonomous/Slamandpath/data_odometry_poses/dataset/poses/00.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCurrent working directory:\u001b[39m\u001b[33m\"\u001b[39m, os.getcwd())  \u001b[38;5;66;03m# Check your working directory\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m poses = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/deepak-bhagat/software/Autonomous/Slamandpath/data_odometry_poses/dataset/poses/00.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use forward slashes for cross-platform support\u001b[39;00m\n\u001b[32m      7\u001b[39m poses.describe()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/Autonomous/Slamandpath/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/Autonomous/Slamandpath/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/Autonomous/Slamandpath/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/Autonomous/Slamandpath/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/Autonomous/Slamandpath/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/deepak-bhagat/software/Autonomous/Slamandpath/data_odometry_poses/dataset/poses/00.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())  # Check your working directory\n",
    "\n",
    "poses = pd.read_csv(\"/home/deepak-bhagat/software/Autonomous/Slamandpath/data_odometry_poses/dataset/poses/00.txt\")  # Use forward slashes for cross-platform support\n",
    "poses.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed628daf-66dc-4a5d-b06d-8100931758df",
   "metadata": {},
   "outputs": [],
   "source": [
    "poses.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193131a2-b344-42de-88eb-7fec2786841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykitti\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the base directory where your KITTI odometry dataset is stored\n",
    "basedir =\"D:\\DSGRMS\\KIITI DataSet\\dataset\"\n",
    "\n",
    "# Specify the sequence you have (e.g., '00')\n",
    "sequence = '00'\n",
    "\n",
    "# If you only have a subset of frames, you can specify it. Otherwise, set frames=None.\n",
    "frames = None\n",
    "\n",
    "# Create an instance of the odometry class\n",
    "data = pykitti.odometry(basedir, sequence)\n",
    "\n",
    "# Since you don't have image files, avoid calling image-related methods.\n",
    "# Instead, work with LiDAR, calibration, timestamps, and poses.\n",
    "\n",
    "# 1. Print basic information\n",
    "print(\"Number of frames:\", len(data))\n",
    "print(\"Calibration data for camera 0 (intrinsics):\\n\", data.calib.K_cam0)\n",
    "print(\"First timestamp:\", data.timestamps[0])\n",
    "if data.poses:\n",
    "    print(\"First ground truth pose:\\n\", data.poses[0])\n",
    "else:\n",
    "    print(\"No ground truth poses available.\")\n",
    "\n",
    "# 2. Access and visualize the first LiDAR scan\n",
    "velo_scan = data.get_velo(0)\n",
    "print(\"Shape of first LiDAR scan:\", velo_scan.shape)  # Expected shape: (N, 4)\n",
    "\n",
    "# Plot a top-down view of the LiDAR scan (using x and y coordinates, color coded by reflectance)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(velo_scan[:, 0], velo_scan[:, 1], s=0.5, c=velo_scan[:, 3], cmap='jet')\n",
    "plt.xlabel(\"X (m)\")\n",
    "plt.ylabel(\"Y (m)\")\n",
    "plt.title(\"Top-Down View of the First LiDAR Scan\")\n",
    "plt.colorbar(label=\"Reflectance\")\n",
    "plt.show()\n",
    "\n",
    "# 3. If you want to iterate over a few LiDAR scans and check their timestamps or poses:\n",
    "for idx, (velo, timestamp) in enumerate(zip(data.velo, data.timestamps)):\n",
    "    print(f\"Frame {idx}: timestamp = {timestamp}\")\n",
    "    # Optionally, do further processing with the LiDAR data\n",
    "    if idx >= 2:  # Process only the first three scans for this example\n",
    "        break\n",
    "\n",
    "# 4. Using calibration to transform a point from the velodyne frame to camera 0 frame:\n",
    "# Create a homogeneous point (in the velodyne coordinate system)\n",
    "point_velo = np.array([0, 0, 0, 1])\n",
    "point_cam0 = data.calib.T_cam0_velo.dot(point_velo)\n",
    "print(\"Point in camera 0 coordinate system:\", point_cam0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05369c-8c00-43f0-9e9e-7585472468da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykitti\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# Set the base directory and sequence for the odometry dataset\n",
    "basedir = 'D:\\DSGRMS\\KIITI DataSet\\dataset'\n",
    "sequence = '00'\n",
    "frames = None  # Load all frames or specify a range, e.g., range(0, 50)\n",
    "\n",
    "# Create an instance of the odometry dataset\n",
    "data = pykitti.odometry(basedir, sequence, frames=frames)\n",
    "\n",
    "# Load the first LiDAR scan from the dataset\n",
    "velo_scan = data.get_velo(6)  # shape: (N, 4) -> [x, y, z, reflectance]\n",
    "\n",
    "# Extract the 3D points (x, y, z)\n",
    "points = velo_scan[:, :3]\n",
    "\n",
    "# Use reflectance for color (scaled to [0,1])\n",
    "reflectance = velo_scan[:, 3]\n",
    "colors = np.tile(reflectance.reshape(-1, 1), (1, 3))\n",
    "colors = colors / np.max(colors)  # Normalize to range [0,1]\n",
    "\n",
    "# Create an Open3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911eb393-47bf-4fe0-9ae8-7def81af3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "velo_scan = data.velo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c2f13-8e7f-4b59-93cd-244a51e1050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(velo_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651cccd-cf04-47a8-9105-1fdedbb97ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.timestamps[4540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90015c-6316-4fb8-a51e-957cc0ec2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pykitti\n",
    "import copy\n",
    "\n",
    "# --- SLAM Setup ---\n",
    "basedir =\"D:\\DSGRMS\\KIITI DataSet\\dataset\"  # Replace with your path\n",
    "sequence = '00'\n",
    "data = pykitti.odometry(basedir, sequence, frames=range(0, 10))  # For demo, use first 10 scans\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size=0.1):\n",
    "    \"\"\" Downsample and estimate normals \"\"\"\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    pcd_down.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30)\n",
    "    )\n",
    "    return pcd_down\n",
    "\n",
    "# Initialize with the first LiDAR scan\n",
    "velo_scan = data.get_velo(0)\n",
    "pcd_prev = o3d.geometry.PointCloud()\n",
    "pcd_prev.points = o3d.utility.Vector3dVector(velo_scan[:, :3])\n",
    "pcd_prev = preprocess_point_cloud(pcd_prev, voxel_size=0.1)\n",
    "\n",
    "transformation_global = np.eye(4)\n",
    "trajectory = [transformation_global.copy()]\n",
    "global_map = copy.deepcopy(pcd_prev)\n",
    "\n",
    "# SLAM Loop (using ICP to register consecutive scans)\n",
    "for i in range(1, 10):\n",
    "    velo_scan = data.get_velo(i)\n",
    "    pcd_curr = o3d.geometry.PointCloud()\n",
    "    pcd_curr.points = o3d.utility.Vector3dVector(velo_scan[:, :3])\n",
    "    pcd_curr = preprocess_point_cloud(pcd_curr, voxel_size=0.1)\n",
    "    \n",
    "    # ICP Registration (point-to-point)\n",
    "    threshold = 1.0  # max correspondence distance\n",
    "    icp_result = o3d.pipelines.registration.registration_icp(\n",
    "        pcd_curr, pcd_prev, threshold, np.eye(4),\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    \n",
    "    # Update global transformation and trajectory\n",
    "    transformation_global = transformation_global @ icp_result.transformation\n",
    "    trajectory.append(transformation_global.copy())\n",
    "    \n",
    "    # Transform current point cloud into the global coordinate frame\n",
    "    pcd_curr_transformed = copy.deepcopy(pcd_curr)\n",
    "    pcd_curr_transformed.transform(transformation_global)\n",
    "    global_map += pcd_curr_transformed\n",
    "    global_map = global_map.voxel_down_sample(0.1)\n",
    "    \n",
    "    # Prepare for next iteration\n",
    "    pcd_prev = pcd_curr\n",
    "    print(f\"Processed frame {i}\")\n",
    "\n",
    "# Visualize the global map and trajectory\n",
    "print(\"Estimated Trajectory Poses:\")\n",
    "for pose in trajectory:\n",
    "    print(pose)\n",
    "\n",
    "o3d.visualization.draw_geometries([global_map])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
